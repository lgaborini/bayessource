<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction • bayessource</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction">
<meta property="og:description" content="bayessource">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bayessource</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.3.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/introduction.html">Introduction</a>
    </li>
    <li>
      <a href="../articles/prior_elicitation.html">Prior elicitation</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="introduction_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction</h1>
                        <h4 class="author">Lorenzo Gaborini</h4>
            
            <h4 class="date">2021-11-05</h4>
      
      
      <div class="hidden name"><code>introduction.Rmd</code></div>

    </div>

    
    

<p>This vignette explains briefly how to use this package.</p>
<div id="package-goal" class="section level1">
<h1 class="hasAnchor">
<a href="#package-goal" class="anchor"></a>Package goal</h1>
<p>The package has been conceived to evaluate the hypothesis whether two sets of items (a reference set and a questioned set) belong to the same population or not.<br>
Each item is described with a vector of <span class="math inline">\(p\)</span> measurements.</p>
<p>The evaluation is performed using Bayesian statistics, particularly Gibbs sampling.</p>
<p>The model we applied is that these populations are represented as samples from Multivariate Gaussian distributions, with unknown means and covariance matrices.</p>
<p>Particular care has been given in order to obtain strongly performing functions. The main core is written using <code>Rcpp</code>.</p>
<p>For more theoretical details, see <span class="citation">(Bozza et al. 2008)</span>.</p>
<div id="package-contents" class="section level2">
<h2 class="hasAnchor">
<a href="#package-contents" class="anchor"></a>Package contents</h2>
<p>The package supplies several functions to compute common densities (e.g. Wishart, Inverted Wishart), and two functions to compute the marginal likelihood of observations, as well as the full Likelihood Ratio (<code><a href="../reference/marginalLikelihood.html">marginalLikelihood()</a></code>, <code><a href="../reference/samesource_C.html">samesource_C()</a></code>).</p>
<div id="main-functions" class="section level3">
<h3 class="hasAnchor">
<a href="#main-functions" class="anchor"></a>Main functions</h3>
<ul>
<li>
<code><a href="../reference/make_priors_and_init.html">make_priors_and_init()</a></code>: obtain hyperpriors and initialization from a background dataset</li>
<li>
<code><a href="../reference/marginalLikelihood.html">marginalLikelihood()</a></code>: fast computation of the marginal likelihood</li>
<li>
<code><a href="../reference/samesource_C.html">samesource_C()</a></code>: fast computation of the Bayes Factor (same source vs. different sources)</li>
<li>
<code><a href="../reference/mcmc_postproc.html">mcmc_postproc()</a></code>: collect and tidy posterior samples from this package</li>
</ul>
</div>
</div>
</div>
<div id="usage" class="section level1">
<h1 class="hasAnchor">
<a href="#usage" class="anchor"></a>Usage</h1>
<p>This section describes the usage on some made-up data.</p>
<div id="sample-data" class="section level2">
<h2 class="hasAnchor">
<a href="#sample-data" class="anchor"></a>Sample data</h2>
<p>We create some dummy data, generated by two bivariate Gaussian distributions with known means and covariances. Covariance matrices are generated using the bundled <code><a href="../reference/rwish.html">rwish()</a></code> function, to obtain invertible matrices with ease.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>

<span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">2</span>
<span class="va">mean.quest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>
<span class="va">mean.ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span>
<span class="va">cov.quest</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rwish.html">rwish</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">cov.ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rwish.html">rwish</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">n.quest</span> <span class="op">&lt;-</span> <span class="fl">20</span>
<span class="va">n.ref</span> <span class="op">&lt;-</span> <span class="va">n.quest</span>

<span class="va">df.quest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="../reference/rmvnorm.html">rmvnorm</a></span><span class="op">(</span><span class="va">n.quest</span>, <span class="va">mean.quest</span>, <span class="va">cov.quest</span><span class="op">)</span><span class="op">)</span>
<span class="va">df.ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="../reference/rmvnorm.html">rmvnorm</a></span><span class="op">(</span><span class="va">n.ref</span>, <span class="va">mean.ref</span>, <span class="va">cov.ref</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Here are the datasets:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X1</span>, y <span class="op">=</span> <span class="va">X2</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">'red'</span>, data <span class="op">=</span> <span class="va">df.quest</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X1</span>, y <span class="op">=</span> <span class="va">X2</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">'blue'</span>, data <span class="op">=</span> <span class="va">df.ref</span><span class="op">)</span></code></pre></div>
<p><img src="introduction_files/figure-html/plot-datasets-1.png" width="700"></p>
<p>It is clear that the two samples come from different populations, hence we expect a low likelihood-ratio value.</p>
</div>
<div id="model-and-prior-specification" class="section level2">
<h2 class="hasAnchor">
<a href="#model-and-prior-specification" class="anchor"></a>Model and prior specification</h2>
<p>The package implements a two-sample Bayesian Hierarchical model with Gaussian multivariate likelihoods, and Inverse-Wishart prior on the covariance matrices.<br>
The theoretical details are specified in <span class="citation">(Bozza et al. 2008)</span>.</p>
<div id="background-model" class="section level3">
<h3 class="hasAnchor">
<a href="#background-model" class="anchor"></a>Background model</h3>
<p>Let us recall the model definition.</p>
<p>We suppose to have background observations from a set of <span class="math inline">\(m\)</span> sources.<br>
Each observation lies in a <span class="math inline">\(p\)</span>-dimensional space.</p>
<p>We note with <span class="math inline">\(X_{ij}\)</span> the <span class="math inline">\(j\)</span>-th sample from the <span class="math inline">\(i\)</span>-th source, <span class="math inline">\(i = 1, \ldots, m\)</span>. The <span class="math inline">\(i\)</span>-th source is assumed to generate data from a Multivariate Normal, with mean vector <span class="math inline">\(\theta_i\)</span>, and covariance matrix <span class="math inline">\(W_i\)</span>.</p>
<p><span class="math display">\[\begin{align}
X_{ij} \; | \; \theta_i, \; W_i &amp;\sim N_p(\theta_i, W_i) \quad \forall j = 1, \ldots, n \\
\theta_i \; | \; \mu, B &amp;\sim N_p(\mu, B) \\
W_i \; | \; U, n_w &amp;\sim IW(U, n_w)
\end{align}\]</span></p>
<p>where <span class="math inline">\(n_w &gt; 2\,p\)</span>, and <span class="math inline">\(U\)</span> is set s.t. <span class="math display">\[E[W_i] = \frac{U}{n_w - 2(p + 1)}\]</span> (parametrization according to <span class="citation">(Press 2012)</span>).</p>
</div>
<div id="computation" class="section level3">
<h3 class="hasAnchor">
<a href="#computation" class="anchor"></a>Computation</h3>
<p>Since the full conditionals are conjugated, a Gibbs sampler can be implemented for this model. See the details in <span class="citation">(Bozza et al. 2008)</span>.</p>
</div>
<div id="prior-elicitation" class="section level3">
<h3 class="hasAnchor">
<a href="#prior-elicitation" class="anchor"></a>Prior elicitation</h3>
<p>As the model is Bayesian, we are required to specify the hyperparameters <span class="math inline">\(\mu, B, U, n_w\)</span>, as well as the Gibbs chain initialization <span class="math inline">\(W_i\)</span>.<br>
Notice that inference is propagated by supplying the <em>inverses</em> of covariance matrices, i.e. <span class="math inline">\(B^{-1}\)</span> and <span class="math inline">\(W_i^{-1}\)</span>.</p>
<p>Example (hyper)priors can be set like this:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fl">0.1</span>
<span class="va">B.inv</span> <span class="op">&lt;-</span> <span class="va">eps</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>
<span class="va">W.inv.1</span> <span class="op">&lt;-</span> <span class="va">eps</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>
<span class="va">W.inv.2</span> <span class="op">&lt;-</span> <span class="va">eps</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>
<span class="va">U</span> <span class="op">&lt;-</span> <span class="va">eps</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>
<span class="va">nw</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="va">p</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span>
<span class="va">mu</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">mean.quest</span> <span class="op">+</span> <span class="va">mean.ref</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span></code></pre></div>
<p>The package proves the function <code><a href="../reference/make_priors_and_init.html">make_priors_and_init()</a></code> to supply these parameters based on a background dataset.</p>
<p>It returns a list containing estimates for <span class="math inline">\(\mu\)</span>, <span class="math inline">\(B^{-1}\)</span>, <span class="math inline">\(U\)</span>, the initialization for <span class="math inline">\(W_i^{-1}\)</span>, and the smallest possible <span class="math inline">\(n_w\)</span> such that the matrices are invertible.</p>
<p>The prior elicitation is described in the dedicated vignette: <code>vignette("Prior elicitation")</code>.</p>
</div>
<div id="observation-model" class="section level3">
<h3 class="hasAnchor">
<a href="#observation-model" class="anchor"></a>Observation model</h3>
<p>The package has been written to evaluate whether <strong>two</strong> sets of observations come from the same source (<span class="math inline">\(H_p\)</span>) or not (<span class="math inline">\(H_d\)</span>). Background information (the hyperparameters) is noted with letter <span class="math inline">\(I = \left\{\mu, B, U, n_w \right\}\)</span>.</p>
<p>We note with <span class="math inline">\(Y_{ij}\)</span> the <span class="math inline">\(j\)</span>-th sample from the <span class="math inline">\(i\)</span>-th considered set, where <span class="math inline">\(i \in [\text{reference}, \text{questioned}]\)</span>.<br>
Collectively, we shorten <span class="math inline">\(Y_i = \left\{ Y_{ij} \right\}_j\)</span>.</p>
</div>
</div>
<div id="bayes-factor" class="section level2">
<h2 class="hasAnchor">
<a href="#bayes-factor" class="anchor"></a>Bayes Factor</h2>
<p>The Bayes Factor for this problem can be written as:</p>
<p><span class="math display">\[\text{BF} = \frac{ p(Y_{\text{reference}}, Y_{\text{questioned}} \mid I, H_p) }{p(Y_{\text{reference}}, Y_{\text{questioned}} \mid I, H_d)}\]</span></p>
<p>Notice that the numerator is a marginal likelihood:</p>
<p><span class="math display">\[p(Y_{\text{reference}}, Y_{\text{questioned}} \mid I, H_p) = \int p( Y_{\text{reference}}, Y_{\text{questioned}} \mid \theta, W ) p(\theta, W \mid \mu, B, U, n_w) \text{ d}\theta \text{ d}W \]</span></p>
<p>and the denominator is a product of marginal likelihoods (assuming independence between sources under <span class="math inline">\(H_d\)</span>):</p>
<p><span class="math display">\[\begin{align}
p(Y_{\text{reference}}, Y_{\text{questioned}} \mid I, H_d) &amp;= 
p(Y_{\text{reference}} \mid I, H_d) p(Y_{\text{questioned}} \mid I, H_d) = \\
&amp;= \left( \int p( Y_{\text{reference}} \mid \theta, W ) p(\theta, W \mid \mu, B, U, n_w) \text{ d}\theta \text{ d}W \right) 
\left( \int p( Y_{\text{questioned}} \mid \theta, W ) p(\theta, W \mid \mu, B, U, n_w) \text{ d}\theta \text{ d}W \right)
\end{align}\]</span></p>
</div>
<div id="computation-1" class="section level2">
<h2 class="hasAnchor">
<a href="#computation-1" class="anchor"></a>Computation</h2>
<p>The marginal likelihood is computed with the function <code><a href="../reference/marginalLikelihood.html">marginalLikelihood()</a></code> from the Gibbs sampler output using <span class="citation">(Chib 1995)</span>.<br>
E.g. here we compute <span class="math inline">\(p(Y_{\text{questioned}} \mid I, H_d)\)</span>:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">burn.in</span> <span class="op">=</span> <span class="fl">1000</span>
<span class="va">n.iter</span> <span class="op">=</span> <span class="fl">10000</span>

<span class="fu"><a href="../reference/marginalLikelihood.html">marginalLikelihood</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.quest</span><span class="op">)</span>, <span class="va">n.iter</span>, <span class="va">B.inv</span>, <span class="va">W.inv.1</span>, <span class="va">U</span>, <span class="va">nw</span>, <span class="va">mu</span>, <span class="va">burn.in</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">## [1] -80.5086</span></code></pre></div>
<p>the LR value can be computed as well, now considering two samples. The function is <code><a href="../reference/samesource_C.html">samesource_C()</a></code>: (<code>W.inv.2</code> is used only for chain initalisation).</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/samesource_C.html">samesource_C</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.quest</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.ref</span><span class="op">)</span>, <span class="va">n.iter</span>, <span class="va">B.inv</span>, <span class="va">W.inv.1</span>, <span class="va">W.inv.2</span>, <span class="va">U</span>, <span class="va">nw</span>, <span class="va">mu</span>, <span class="va">burn.in</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">## [1] -8.670725</span></code></pre></div>
<p>Notice how low it is compared to using a subset of the reference data as the questioned items (same source, supporting <span class="math inline">\(H_p\)</span>):</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/samesource_C.html">samesource_C</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.ref</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">20</span>,<span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.ref</span><span class="op">)</span>, <span class="va">n.iter</span>, <span class="va">B.inv</span>, <span class="va">W.inv.1</span>, <span class="va">W.inv.2</span>, <span class="va">U</span>, <span class="va">nw</span>, <span class="va">mu</span>, <span class="va">burn.in</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">## [1] 22.02843</span></code></pre></div>
<p>All marginal likelihoods in the BF formula can also be obtained by specifying <code>marginals = TRUE</code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/samesource_C.html">samesource_C</a></span><span class="op">(</span>
   <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.quest</span><span class="op">)</span>,
   <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.ref</span><span class="op">)</span>, 
   <span class="va">n.iter</span>, <span class="va">B.inv</span>, <span class="va">W.inv.1</span>, <span class="va">W.inv.2</span>, <span class="va">U</span>, <span class="va">nw</span>, <span class="va">mu</span>, <span class="va">burn.in</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span>, marginals <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="co">## $value</span>
<span class="co">## [1] -8.663289</span>
<span class="co">## </span>
<span class="co">## $log_ml_Hp</span>
<span class="co">## [1] -200.5255</span>
<span class="co">## </span>
<span class="co">## $log_ml_Hd_ref</span>
<span class="co">## [1] -111.368</span>
<span class="co">## </span>
<span class="co">## $log_ml_Hd_quest</span>
<span class="co">## [1] -80.49428</span></code></pre></div>
</div>
</div>
<div id="diagnostics" class="section level1">
<h1 class="hasAnchor">
<a href="#diagnostics" class="anchor"></a>Diagnostics</h1>
<p>The package supports the output of the entire chain for <span class="math inline">\(\theta_i\)</span> and <span class="math inline">\(W^{-1}_i\)</span> (i.e., the inverse of <span class="math inline">\(W_i\)</span>).</p>
<p>At the time, this is possible only during the computation of a single marginal likelihood, in this case the one related to the sample from the questioned population, namely:</p>
<p><span class="math inline">\(\left( \int p( Y_{\text{questioned}} \mid \theta, W ) p(\theta, W \mid \mu, B, U, n_w) \text{ d}\theta \text{ d}W \right)\)</span></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/marginalLikelihood.html">marginalLikelihood</a></span><span class="op">(</span>
   <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df.quest</span><span class="op">)</span>, 
   <span class="va">n.iter</span>, <span class="va">B.inv</span>, <span class="va">W.inv.1</span>, <span class="va">U</span>, <span class="va">nw</span>, <span class="va">mu</span>, <span class="va">burn.in</span>, 
   output.mcmc <span class="op">=</span> <span class="cn">TRUE</span>
   <span class="op">)</span></code></pre></div>
<p>Notice that <code>results</code> now is a <code>list</code>, where <code>results$value</code> holds the marginal likelihood value, and <code>results$mcmc</code> is the <a href="https://cran.r-project.org/web/packages/coda/index.html"><code>coda</code></a> object which holds the chain output.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">mcmc</span>, <span class="fl">4</span><span class="op">)</span></code></pre></div>
<pre><code>## Markov Chain Monte Carlo (MCMC) output:
## Start = 1001 
## End = 1005 
## Thinning interval = 1 
##          theta.1    theta.2  W.inv.1   W.inv.2   W.inv.3   W.inv.4
## [1,]  0.27705514 -0.6446322 3.233887 0.9673711 0.9673711 0.5883328
## [2,]  0.05410904 -1.5346673 1.405348 0.3767320 0.3767320 0.5773098
## [3,]  0.36381261 -0.8899626 1.916730 0.7619017 0.7619017 0.6600169
## [4,]  0.00767722 -0.9441759 3.344633 1.4356383 1.4356383 0.9910974
## [5,] -0.12565367 -0.3843985 4.088822 1.0591426 1.0591426 0.5582402</code></pre>
<p>Remember that R is column-major: <code>W.inv.1</code> is <span class="math inline">\(W^{-1}_1(1,1)\)</span>, <code>W.inv.2</code> is <span class="math inline">\(W^{-1}_1(2,1)\)</span> and so on.</p>
<p>Using standard <code>coda</code> tools, we can perform diagnostics, such as summaries:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">coda</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">mcmc</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## Iterations = 1001:10000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 9000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##            Mean     SD Naive SE Time-series SE
## theta.1  0.1778 0.1859 0.001960       0.001960
## theta.2 -1.0684 0.3925 0.004137       0.004045
## W.inv.1  3.2082 0.8828 0.009305       0.009608
## W.inv.2  1.0526 0.3567 0.003759       0.003958
## W.inv.3  1.0526 0.3567 0.003759       0.003958
## W.inv.4  0.6992 0.1938 0.002043       0.002151
## 
## 2. Quantiles for each variable:
## 
##            2.5%      25%     50%     75%  97.5%
## theta.1 -0.1879  0.05617  0.1784  0.3000  0.542
## theta.2 -1.8482 -1.32138 -1.0731 -0.8112 -0.299
## W.inv.1  1.7321  2.56552  3.1294  3.7571  5.131
## W.inv.2  0.4544  0.80098  1.0196  1.2662  1.860
## W.inv.3  0.4544  0.80098  1.0196  1.2662  1.860
## W.inv.4  0.3747  0.55829  0.6818  0.8214  1.131</code></pre>
<p>and traceplots:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/coda/man/traceplot.html">traceplot</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">mcmc</span><span class="op">)</span></code></pre></div>
<p><img src="introduction_files/figure-html/unnamed-chunk-11-1.png" width="700"><img src="introduction_files/figure-html/unnamed-chunk-11-2.png" width="700"><img src="introduction_files/figure-html/unnamed-chunk-11-3.png" width="700"><img src="introduction_files/figure-html/unnamed-chunk-11-4.png" width="700"><img src="introduction_files/figure-html/unnamed-chunk-11-5.png" width="700"><img src="introduction_files/figure-html/unnamed-chunk-11-6.png" width="700"></p>
<p>We can recover the original matrices by hand, reshaping the desired columns (e.g. for <code>W.inv</code>) into a matrix/3D array:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n.samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">mcmc</span><span class="op">)</span>
<span class="va">W.inv.samples</span> <span class="op">&lt;-</span> <span class="va">results</span><span class="op">$</span><span class="va">mcmc</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">'W.inv.'</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">p</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">W.inv.samples</span>, <span class="fl">5</span><span class="op">)</span></code></pre></div>
<pre><code>## Markov Chain Monte Carlo (MCMC) output:
## Start = 1001 
## End = 1006 
## Thinning interval = 1 
##       W.inv.1   W.inv.2   W.inv.3   W.inv.4
## [1,] 3.233887 0.9673711 0.9673711 0.5883328
## [2,] 1.405348 0.3767320 0.3767320 0.5773098
## [3,] 1.916730 0.7619017 0.7619017 0.6600169
## [4,] 3.344633 1.4356383 1.4356383 0.9910974
## [5,] 4.088822 1.0591426 1.0591426 0.5582402
## [6,] 3.095175 0.6505246 0.6505246 0.4239867</code></pre>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">W.inv.samples.cube</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="va">W.inv.samples</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n.samples</span>, <span class="va">p</span>, <span class="va">p</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">W.inv.samples.cube</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 9000    2    2</code></pre>
<p>or using the supplied post-processing function <code><a href="../reference/mcmc_postproc.html">mcmc_postproc()</a></code>:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">list.postproc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mcmc_postproc.html">mcmc_postproc</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">mcmc</span>, compute.ML <span class="op">=</span> <span class="cn">TRUE</span>, cumulative <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">list.postproc</span><span class="op">$</span><span class="va">theta.samples</span><span class="op">)</span></code></pre></div>
<pre><code>##  'mcmc' num [1:9000, 1:2] 0.27706 0.05411 0.36381 0.00768 -0.12565 ...
##  - attr(*, "dimnames")=List of 2
##   ..$ : NULL
##   ..$ : chr [1:2] "theta.1" "theta.2"
##  - attr(*, "mcpar")= num [1:3] 1001 10000 1</code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">list.postproc</span><span class="op">$</span><span class="va">W.samples</span><span class="op">)</span></code></pre></div>
<pre><code>##  num [1:9000, 1:2, 1:2] 0.609 0.862 0.964 0.79 0.481 ...</code></pre>
<p>It also allows for easy computation of posterior point estimators:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">list.postproc</span><span class="op">$</span><span class="va">theta.samples.ML</span></code></pre></div>
<pre><code>## [1]  0.1777568 -1.0683701</code></pre>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">list.postproc</span><span class="op">$</span><span class="va">W.samples.ML</span></code></pre></div>
<pre><code>##           [,1]      [,2]
## [1,]  0.696931 -1.050408
## [2,] -1.050408  3.198459</code></pre>
<p>More advanced diagnostics are available with the recent {<a href="https://mc-stan.org/bayesplot/">bayesplot</a>} package:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/message.html">suppressPackageStartupMessages</a></span><span class="op">(</span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/bayesplot/">bayesplot</a></span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>

<span class="fu">bayesplot</span><span class="fu">::</span><span class="fu">mcmc_areas</span><span class="op">(</span>x <span class="op">=</span> <span class="va">results</span><span class="op">$</span><span class="va">mcmc</span><span class="op">)</span></code></pre></div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-Bozza2008Probabilistic">
<p>Bozza, Silvia, Franco Taroni, Raymond Marquis, and Matthieu Schmittbuhl. 2008. “Probabilistic Evaluation of Handwriting Evidence: Likelihood Ratio for Authorship.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 57 (3): 329–41. <a href="https://doi.org/10.1111/j.1467-9876.2007.00616.x">https://doi.org/10.1111/j.1467-9876.2007.00616.x</a>.</p>
</div>
<div id="ref-Chib1995Marginal">
<p>Chib, Siddhartha. 1995. “Marginal Likelihood from the Gibbs Output.” <em>Journal of the American Statistical Association</em> 90 (432): 1313–21. <a href="http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635">http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635</a>.</p>
</div>
<div id="ref-Press2012Applied">
<p>Press, S James. 2012. <em>Applied Multivariate Analysis: Using Bayesian and Frequentist Methods of Inference</em>. Courier Corporation.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Lorenzo Gaborini.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
